{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import struct\n",
    "from os import system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integers_list = range(1,10)\n",
    "\n",
    "output_file = \"data_int.txt\"\n",
    "\n",
    "with open(output_file, 'w') as out_file:\n",
    "  for line in integers_list:\n",
    "    out_file.write(str(line) + '\\n') \n",
    "# i use windows, so i should use \"!type\" except for \"!cat\"\n",
    "!type data_int.txt\n",
    "print('---------------------------------------------------------')\n",
    "#---------------------------------------------------------------\n",
    "matrix = np.random.random(size=(5,5))\n",
    "\n",
    "output_file = \"data_float.txt\"\n",
    "\n",
    "with open(output_file, 'w') as out_file:\n",
    "  for line in matrix:\n",
    "    out_file.write(str(line) + '\\n') \n",
    "\n",
    "!type data_float.txt\n",
    "print('---------------------------------------------------------')\n",
    "#---------------------------------------------------------------\n",
    "df = pd.read_fwf('data_float.txt')\n",
    "df.to_csv('data_float.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file *user_data.json*, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "data = json.load(open('C:/Users/sina tavakoli/Desktop/user_data.json'))\n",
    "# print(data)\n",
    "for parsedData in data:\n",
    "    if (parsedData['CreditCardType'] == 'American Express'):\n",
    "        result.append(parsedData)\n",
    "\n",
    "df = pd.DataFrame(data=result)\n",
    "df.to_csv(\"resulted_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_csv('C:/Users/sina tavakoli/Desktop/mushrooms_categorized.csv')\n",
    "avg_data = data.groupby(['class']).mean()\n",
    "avg_data.to_json(\"mushrooms_categorized.json\", orient=\"columns\")\n",
    "print(data)\n",
    "avg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named *credit_card.dat* from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_file = \"C:/Users/sina tavakoli/Desktop/credit_card.dat\"\n",
    "with open(master_file, 'r') as out_file:\n",
    "    for line in out_file:\n",
    "        print(''.join([chr(int(line[i:i+6],2)) for i in range(0, len(line), 6)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/data_format.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, ``pack'' the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_OSEMN.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "master_data = pd.read_csv(\"C:/Users/sina tavakoli/Desktop/data_000637.txt\", nrows = 10)\n",
    "print(master_data)\n",
    "\n",
    "data = pd.read_csv(\"C:/Users/sina tavakoli/Desktop/data_000637.txt\")\n",
    "\n",
    "with open(\"binary_file.dat\", \"wb\") as binary_file:\n",
    "    for i in range(len(data[\"HEAD\"])):\n",
    "        \n",
    "        x1 = 1 << 62\n",
    "        fpga = data.loc[data.index[i],\"FPGA\"] << 58\n",
    "        tdcc = data.loc[data.index[i],\"TDC_CHANNEL\"] << 49\n",
    "        orbit = data.loc[data.index[i],\"ORBIT_CNT\"] << 17\n",
    "        bx = data.loc[data.index[i],\"BX_COUNTER\"] << 5\n",
    "        tdcm = data.loc[data.index[i],\"TDC_MEAS\"]\n",
    "        wordr = x1|fpga|tdcc|orbit|bx|tdcm\n",
    "        wordx = x1^fpga^tdcc^orbit^bx^tdcm        \n",
    "        aux1 = int(wordr & 0xFFFFFFFF)\n",
    "        aux2 = int((wordr >> 32) & 0xFFFFFFFF)\n",
    "        binary_file.write(struct.pack(\"<q\",aux1))\n",
    "binary_file.close()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "82d66711803cd90d2df8927f41b79f4324b010080e429a0bb8838d6093cd1ef3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
