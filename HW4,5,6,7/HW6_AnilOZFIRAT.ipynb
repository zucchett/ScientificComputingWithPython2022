{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_int = [1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "i = open(\"data_int.txt\", \"w\")\n",
    "i.write(str(data_int))\n",
    "i.close()\n",
    "\n",
    "!type \".\\data_int.txt\"\n",
    "\n",
    "\n",
    "data_float = np.random.random((5,5))\n",
    "f = open(\"data_float.txt\", \"w\")\n",
    "f.write(str(data_float))\n",
    "f.close\n",
    "\n",
    "!type \".\\data_float.txt\"\n",
    "\n",
    "read_int_file = pd.read_csv (r\"D:\\Desktop\\FirstSemester\\SCwP Exercise\\CopyOnes\\06ex\\data_int.txt\")\n",
    "read_int_file.to_csv (r\"D:\\Desktop\\FirstSemester\\SCwP Exercise\\CopyOnes\\06ex\\data_int.csv\", index=None)\n",
    "\n",
    "read_float_file = pd.read_csv (r\"D:\\Desktop\\FirstSemester\\SCwP Exercise\\CopyOnes\\06ex\\data_float.txt\")\n",
    "read_float_file.to_csv (r\"D:\\Desktop\\FirstSemester\\SCwP Exercise\\CopyOnes\\06ex\\data_float.txt\", index=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file *user_data.json*, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\"\n",
    "#data = pd.read_json(url) # use sep=\",\" for coma separation. \n",
    "\n",
    "data = pd.read_json(\"user_data.json\")\n",
    "american = data[data[\"CreditCardType\"] == \"American Express\"]\n",
    "pd.DataFrame(american).to_csv('American Express.csv') \n",
    "display(american)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "data = pd.read_csv(\"mushrooms_categorized.csv\")\n",
    "\n",
    "def average(input):\n",
    "    return data.groupby([input]).mean()\n",
    "\n",
    "#print(\"Class Name:\",i,\"\\n\")\n",
    "#print(average(\"class\"))\n",
    "display(average(\"class\"))\n",
    "pd.DataFrame(average(\"class\")).to_json('mushroomns_categorized.json')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named *credit_card.dat* from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv  \n",
    "\n",
    "data = open(\"credit_card.dat\", \"r\").readlines()\n",
    "\n",
    "credit_cards = []\n",
    "for a in data:\n",
    "    n = 6    # 6 bit binary representation\n",
    "    bin = [a[i:i+n] for i in range(0, len(a)-5, n)]  # -5 because of \\n \n",
    "    number = \"\"\n",
    "    for char in bin:\n",
    "        number += chr(int(char,2))\n",
    "\n",
    "    credit_cards.append(number)\n",
    "credit_cards\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HEAD FPGA CHANNEL   ORBIT_CNT BX_CNT TDC_MEAS\n",
      "0    1    0     123  3869200167   2374       26\n",
      "1    1    0     124  3869200167   2374       27\n",
      "2    1    0      63  3869200167   2553       28\n",
      "3    1    0      64  3869200167   2558       19\n",
      "4    1    0      64  3869200167   2760       25\n",
      "5    1    0      63  3869200167   2762        4\n",
      "6    1    0      61  3869200167   2772       14\n",
      "7    1    0     139  3869200167   2776        0\n",
      "8    1    0      62  3869200167   2774       21\n",
      "9    1    0      60  3869200167   2788        7\n",
      "   HEAD  FPGA  TDC_CHANNEL   ORBIT_CNT  BX_COUNTER  TDC_MEAS\n",
      "0     1     0          123  3869200167        2374        26\n",
      "1     1     0          124  3869200167        2374        27\n",
      "2     1     0           63  3869200167        2553        28\n",
      "3     1     0           64  3869200167        2558        19\n",
      "4     1     0           64  3869200167        2760        25\n",
      "5     1     0           63  3869200167        2762         4\n",
      "6     1     0           61  3869200167        2772        14\n",
      "7     1     0          139  3869200167        2776         0\n",
      "8     1     0           62  3869200167        2774        21\n",
      "9     1     0           60  3869200167        2788         7\n",
      "\n",
      "The .txt file's size:  344  B\n",
      "\n",
      "The .dat file's size:  10.0  MB\n",
      "\n",
      "The difference between the file sizes as MB:  -9.999671936035156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AnilOzfirat\\AppData\\Local\\Temp\\ipykernel_15600\\3830809893.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(entry, ignore_index=True)\n",
      "C:\\Users\\AnilOzfirat\\AppData\\Local\\Temp\\ipykernel_15600\\3830809893.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(entry, ignore_index=True)\n",
      "C:\\Users\\AnilOzfirat\\AppData\\Local\\Temp\\ipykernel_15600\\3830809893.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(entry, ignore_index=True)\n",
      "C:\\Users\\AnilOzfirat\\AppData\\Local\\Temp\\ipykernel_15600\\3830809893.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(entry, ignore_index=True)\n",
      "C:\\Users\\AnilOzfirat\\AppData\\Local\\Temp\\ipykernel_15600\\3830809893.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(entry, ignore_index=True)\n",
      "C:\\Users\\AnilOzfirat\\AppData\\Local\\Temp\\ipykernel_15600\\3830809893.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(entry, ignore_index=True)\n",
      "C:\\Users\\AnilOzfirat\\AppData\\Local\\Temp\\ipykernel_15600\\3830809893.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(entry, ignore_index=True)\n",
      "C:\\Users\\AnilOzfirat\\AppData\\Local\\Temp\\ipykernel_15600\\3830809893.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(entry, ignore_index=True)\n",
      "C:\\Users\\AnilOzfirat\\AppData\\Local\\Temp\\ipykernel_15600\\3830809893.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(entry, ignore_index=True)\n",
      "C:\\Users\\AnilOzfirat\\AppData\\Local\\Temp\\ipykernel_15600\\3830809893.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(entry, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/data_format.png\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv  \n",
    "import struct\n",
    "import os\n",
    "\n",
    "file_name = \"data_000637.txt\" \n",
    "file_dat = \"data_000637.dat\"\n",
    "A=10\n",
    "df_c = pd.read_csv(file_name, nrows=10)\n",
    "\n",
    "\n",
    "with open('data_000637_binary.dat', 'wb') as binary_file:    \n",
    "    \n",
    "    for index, row in df_c.iterrows():\n",
    "        word = 0\n",
    "        word = (row['HEAD'] << 62) | word\n",
    "        word = (row['FPGA'] << 58) | word\n",
    "        word = (row['TDC_CHANNEL'] << 49) | word\n",
    "        word = (row['ORBIT_CNT'] << 17) | word\n",
    "        word = (row['BX_COUNTER'] << 5 ) | word\n",
    "        word = (row['TDC_MEAS'] << 0 ) | word\n",
    "        binary_file.write(struct.pack(\"<q\", word))\n",
    "        \n",
    "data = {}\n",
    "columns = ['HEAD', 'FPGA', 'CHANNEL', 'ORBIT_CNT', 'BX_CNT', 'TDC_MEAS']\n",
    "df = pd.DataFrame({}, columns=columns)\n",
    "\n",
    "with open('data_000637_binary.dat', 'rb') as file:\n",
    "    file_content = file.read()\n",
    "    cnt = 0\n",
    "    word_size = 8\n",
    "    \n",
    "    for i in range(0, len(file_content), word_size):\n",
    "        \n",
    "        cnt= cnt+1\n",
    "        if cnt > 10: break\n",
    "        word = struct.unpack(\"<q\", file_content[i : i + word_size])[0] \n",
    "        head     = (word >> 62) & 0x3\n",
    "        fpga     = (word >> 58) & 0xF\n",
    "        tdc_chan = (word >> 49) & 0x1FF\n",
    "        orb_cnt  = (word >> 17) & 0xFFFFFFFF\n",
    "        bx       = (word >> 5 ) & 0xFFF\n",
    "        tdc_meas = (word >> 0 ) & 0x1F\n",
    "        entry = {'HEAD' : head, 'FPGA' : fpga, 'CHANNEL' : tdc_chan, 'ORBIT_CNT' : orb_cnt, 'BX_CNT' : bx, 'TDC_MEAS' : tdc_meas}\n",
    "        df = df.append(entry, ignore_index=True)\n",
    "        if cnt > 10: \n",
    "            break\n",
    "      \n",
    "print(df)\n",
    "print(df_c)\n",
    "\n",
    "df1 = pd.read_csv(file_name, nrows = 10)\n",
    "df1.to_csv(r\"./data_000637_new.txt\")\n",
    "new=\"./data_000637_new.txt\"\n",
    "        \n",
    "data_000637_txt = os.stat(new)\n",
    "data_000637_binary_dat = os.stat(file_dat)\n",
    "\n",
    "print(\"\\nThe .txt file's size: \", (data_000637_txt.st_size),\" B\\n\")\n",
    "print(\"The .dat file's size: \", ((data_000637_binary_dat.st_size)/(1024*1024)),\" MB\\n\")\n",
    "print(\"The difference between the file sizes as MB: \", ((data_000637_txt.st_size-data_000637_binary_dat.st_size)/(1024**2)))\n",
    "\n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, ``pack'' the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_OSEMN.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
