{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [1,2,3,4,5,6]\n",
    "print(type(a_list[0]))\n",
    "with open('data_int.txt', 'w') as f:\n",
    "    for item in a_list:\n",
    "        f.write(\"%s \" % item)\n",
    "!cat data_int.txt\n",
    "\n",
    "s = np.random.random((5,5))\n",
    "mt = np.matrix(s)\n",
    "with open('data_float.txt','wb') as f:\n",
    "    for line in mt:\n",
    "        np.savetxt(f, line, fmt='%.2f')\n",
    "        \n",
    "!cat data_float.txt     \n",
    "\n",
    "import csv\n",
    "import zlib\n",
    "\n",
    "with open('data_float.txt', 'r') as in_file:\n",
    "    lines = in_file.read().splitlines()\n",
    "    sp = [line.replace(\",\",\" \").split() for line in lines]\n",
    "    gp = zip(*[sp]*1)\n",
    "    with open('data_float.csv', 'w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        for group in gp:\n",
    "            writer.writerows(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file *user_data.json*, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv  \n",
    "import json \n",
    "data = json.load(open('user_data.json'))\n",
    "a1 = []\n",
    "\n",
    "hd = [\"CreditCardType\",\"ID\",\"JobTitle\",\"EmailAddress\",\"FirstNameLastName\",\"CreditCard\"]\n",
    "\n",
    "for i in range (len(data)):\n",
    "    if data[i][\"CreditCardType\"] == \"American Express\":\n",
    "        print(\"The User with Credit Type:{}, ID:{}, Job Title:{}, email adress:{},Name:{},Credit Card:{} .\".format(data[i][\"CreditCardType\"],data[i][\"ID\"],data[i][\"JobTitle\"],data[i][\"EmailAddress\"],data[i][\"FirstNameLastName\"],data[i][\"CreditCard\"]))\n",
    "        array = [data[i][\"CreditCardType\"],data[i][\"ID\"],data[i][\"JobTitle\"],data[i][\"EmailAddress\"],data[i][\"FirstNameLastName\"],data[i][\"CreditCard\"]]\n",
    "        a1.append(array)\n",
    "        a1.append(\"\\n\")\n",
    "\n",
    "with open('new_user_data.csv', 'w', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(hd)\n",
    "    writer.writerow(a1)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = pd.read_csv(\"mushrooms_categorized.csv\") \n",
    "g = data.groupby('class')\n",
    "cl0 = g.get_group(0)   \n",
    "mc0 = cl0.mean()\n",
    "print(\"Mean values for the class 0:\\n\",mc0,\"\\n\")\n",
    "mcj0 = mc0.to_json()\n",
    "jsonString0 = json.dumps(mcj0)\n",
    "jsonFile0 = open(\"mean_class0_json1.json\", \"w\")\n",
    "jsonFile0.write(jsonString0)\n",
    "jsonFile0.close()\n",
    "\n",
    "class1 = g.get_group(1)   \n",
    "mean_class1 = class1.mean()\n",
    "print(\"Mean values for the class 1:\\n\",mean_class1)         \n",
    "mean_class1_json1 = mean_class1.to_json()\n",
    "jsonString = json.dumps(mean_class1_json1)\n",
    "jsonFile = open(\"mean_class1_json1.json\", \"w\")\n",
    "jsonFile.write(jsonString)\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named *credit_card.dat* from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credit_card.dat','rb') as read_dat:\n",
    "    line = read_dat.readlines() \n",
    "    for row in line:\n",
    "        if(len(row) > 5): \n",
    "            u2s = row.decode(\"utf-8\")\n",
    "            u2s = u2s[0:114]   \n",
    "            start_digit = 0\n",
    "            ds = 6\n",
    "            cd=[]\n",
    "            for i in range(19):\n",
    "                end_digit = start_digit + ds\n",
    "                digits_4 = u2s[start_digit:(start_digit + ds)]\n",
    "                cd.append(digits_4)\n",
    "                start_digit = start_digit + ds                \n",
    "            credit_card = \"\"\n",
    "            counter = 1\n",
    "            for i in range(0,19):\n",
    "                credit_card = credit_card + chr(int(cd[i],2))\n",
    "            print(\"#Credit Card is :\",credit_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/data_format.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, ``pack'' the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_OSEMN.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
